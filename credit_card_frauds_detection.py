# -*- coding: utf-8 -*-
"""Credit_card_frauds_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DrMSxpOwaTuJTpMn_IrnXWrMQ2WX7B2a

**Credit card frauds**

This dataset is unbalanced which means using the data as it is might result in unwanted behaviour from a supervised classifier. To make it easy to understand if a classifier were to train with this data set trying to achieve the best accuracy possible it would most likely label every transaction as a non-fraud
"""

#https://www.kaggle.com/code/pierra/credit-card-dataset-svm-classification/inputi
import pandas as pd
df = pd.read_csv(r'/content/creditcard.csv')
df.head()

df.shape

df.isnull().sum()

df.info()

df['Class'].value_counts()

number_no_fraud = df[df.Class==0]
number_fraud = df[df.Class==1]

print('There are only '+ str(len(number_fraud)) + ' frauds in the original dataset, even though there are ' + str(len(number_no_fraud)) +' no frauds in the dataset.')

import matplotlib.pyplot as plt
plt.figure(figsize=(15,10))
plt.scatter(number_fraud['Time'], number_fraud['Amount']) # Display fraud amounts according to their time
plt.title('Scratter plot amount fraud')
plt.xlabel('Time')
plt.ylabel('Amount')
plt.xlim([0,175000])
plt.ylim([0,2500])

print(number_no_fraud.shape)
print(number_fraud.shape)

number_no_fraud.Amount.describe()

number_fraud.Amount.describe()

"""Correlation of features"""

df_corr = df.corr()

import seaborn
plt.figure(figsize=(15,10))
seaborn.heatmap(df_corr, cmap="YlGnBu")
seaborn.set(font_scale=2,style='white')

plt.title('Heatmap correlation')

#Compare Values for both Transaction
df.groupby('Class').mean()

#Fraud Transaction are 492
#We will choose 492 random Transaction from legit transaction and join in legit data
#This makes a uniformly distributed dataset which is good for modelling
Legit_sample = number_no_fraud.sample(n=492)

newdf = pd.concat([Legit_sample,number_fraud],axis=0)

newdf.tail(5)

newdf['Class'].value_counts()

#Compare Values for both Transaction
newdf.groupby('Class').mean()

x = newdf.drop('Class',axis=1)
y = newdf['Class']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,stratify=y,random_state=42)

print(x.shape , x_train.shape , x_test.shape)

from sklearn.linear_model import LogisticRegression
model_log = LogisticRegression(max_iter=1000)#max_iter=1000
model_log.fit(x_train,y_train)

y_pred_log_test = model_log.predict(x_test)
y_pred_log_test[:5]

y_pred_log_train = model_log.predict(x_train)
y_pred_log_train[:5]

from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
cms = confusion_matrix(y_test,y_pred_log_test)
print(cms)
print("Accuracy on Training Data : " , accuracy_score(y_train,y_pred_log_train))
print("Accuracy on Testing Data : " , accuracy_score(y_test,y_pred_log_test))

print('We have detected ' + str(cms[1][1]) + ' frauds / ' + str(cms[1][1]+cms[1][0]) + ' total frauds.')
print("So, the probability to detect a fraud is " ,accuracy_score(y_train,y_pred_log_train))
print("the accuracy is : ",accuracy_score(y_test,y_pred_log_test))

import seaborn as sns
sns.heatmap(cms, cmap="YlGnBu")
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.tight_layout()

X = df.drop('Class', axis=1)
Y = df['Class']

from imblearn.over_sampling import SMOTE
sm = SMOTE()
X_res, y_res = sm.fit_resample(X, Y)

X_trains, X_tests, Y_trains, Y_tests = train_test_split(X_res, y_res, test_size=0.3, random_state=42)

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier

model_dtc = DecisionTreeClassifier(max_depth=5)
model_dtc.fit(X_trains, Y_trains)
y_pred_dtc = model_dtc.predict(X_tests)

print("Decision Tree Report:\n", classification_report(Y_tests, y_pred_dtc))
cm_dtc = confusion_matrix(Y_tests,y_pred_dtc)
print(cm_dtc)

print('We have detected ' + str(cm_dtc[1][1]) + ' frauds / ' + str(cm_dtc[1][1]+cm_dtc[1][0]) + ' total frauds.')
print("the accuracy is : ",accuracy_score(Y_tests,y_pred_dtc))

"""K-Nearest Neighbors (KNN)"""

from sklearn.neighbors import KNeighborsClassifier

model_knn = KNeighborsClassifier(n_neighbors=5)
model_knn.fit(X_trains, Y_trains)
y_pred_knn = model_knn.predict(X_tests)

print("KNN Report:\n", classification_report(Y_tests, y_pred_knn))
cm_knn = confusion_matrix(Y_tests,y_pred_knn)
print(cm_knn)

print('We have detected ' + str(cm_knn[1][1]) + ' frauds / ' + str(cm_knn[1][1]+cm_knn[1][0]) + ' total frauds.')
print("the accuracy is : ",accuracy_score(Y_tests,y_pred_knn))

"""SVM model apply"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_trains = scaler.fit_transform(X_trains)
X_tests = scaler.transform(X_tests)

from sklearn.svm import SVC
model = SVC()
model.fit(X_trains, Y_trains)

y_pred = model.predict(x_test)
y_pred[:5]

from sklearn.metrics import accuracy_score,confusion_matrix
cm = confusion_matrix(y_test,y_pred)
print(cm)
print("Accuracy on Training Data for LogisticRegression : " , accuracy_score(y_train,y_pred_log_train))
accuracy_score(y_test,y_pred)

print('We have detected ' + str(cm[1][1]) + ' frauds / ' + str(cm[1][1]+cm[1][0]) + ' total frauds.')

import seaborn as sns
sns.heatmap(cm, cmap="YlGnBu")
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.tight_layout()

model1 = SVC(kernel="poly")
model1.fit(x_train,y_train)

y_pred_poly = model1.predict(x_test)
cm_p = confusion_matrix(y_test,y_pred_poly)
print(cm_p)
accuracy_score(y_test,y_pred_poly)

print('We have detected ' + str(cm_p[1][1]) + ' frauds / ' + str(cm_p[1][1]+cm_p[1][0]) + ' total frauds.')

sns.heatmap(cm_p, cmap="YlGnBu")
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.tight_layout()

# svm_model = SVC(kernel="linear")
# svm_model.fit(x_train, y_train)

# y_pred_linear = svm_model.predict(x_test)
# accuracy_score(y_test, y_pred_linear)

svm_model1 = SVC(kernel="rbf", C=100)
svm_model1.fit(x_train, y_train)

y_pred_rbf = svm_model1.predict(x_test)
cm_rbf = confusion_matrix(y_test,y_pred_rbf)
print(cm_rbf)
accuracy_score(y_test, y_pred_rbf)

print('We have detected ' + str(cm_rbf[1][1]) + ' frauds / ' + str(cm_rbf[1][1]+cm_rbf[1][0]) + ' total frauds.')

sns.heatmap(cm_rbf, cmap="YlGnBu")
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.tight_layout()

svm_model2 = SVC(kernel="sigmoid", C=100)
svm_model2.fit(x_train, y_train)

y_pred_sigmoid = svm_model2.predict(x_test)
cm_sig = confusion_matrix(y_test,y_pred_sigmoid)
print(cm_sig)
accuracy_score(y_test, y_pred_sigmoid)

print('We have detected ' + str(cm_sig[1][1]) + ' frauds / ' + str(cm_sig[1][1]+cm_sig[1][0]) + ' total frauds.')

sns.heatmap(cm_sig, cmap="YlGnBu")
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.tight_layout()

"""Overall Final Status:-

**LogisticRegression:**
- We have detected 93 frauds / 98 total frauds.
- So, the probability to detect a fraud is  0.9479034307496823
- the accuracy is :  0.9695431472081218

**Decision Tree**

- We have detected 82082 frauds / 85440 total frauds.
- the accuracy is :  0.9706722004349636

**K-Nearest Neighbors (KNN)**

- We have detected 83284 frauds / 85440 total frauds.
- the accuracy is :  0.9599681104877805

**SVC**

- We have detected 0 frauds / 98 total frauds.
- Accuracy : 0.5025380710659898

**SVM in poly**

- We have detected 71 frauds / 98 total frauds.
- Accuracy : 0.5126903553299492

**SVM in rbf**

- We have detected 27 frauds / 98 total frauds.
- Accuracy : 0.5279187817258884

**SVM in sigmoid**

- We have detected 45 frauds / 98 total frauds.
- Accuracy : 0.49238578680203043
"""